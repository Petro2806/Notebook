\chapter{Convolutions}

\kactlimport[-l hpp]{fft.hpp}
%\import{fft-text.txt}
\kactlimport[-l hpp]{inverse.hpp}
\kactlimport[-l hpp]{exp-log.hpp}
\kactlimport[-l hpp]{modulo.hpp}
\kactlimport[-l hpp]{multipoint-eval.hpp}
\kactlimport[-l hpp]{newton.hpp}
\kactlimport[-l hpp]{berlekamp-massey.hpp}
\kactlimport[-l hpp]{botsan-mori.hpp}

\section{Walsh-Hadamard}
\kactlimport[-l hpp]{conv-xor.hpp}
\kactlimport[-l hpp]{conv-and.hpp}
\kactlimport[-l hpp]{conv-or.hpp}

\subsubsection{Binpow optimization}
You can binpow in xor(and, or)-mult in $O(nlogn)$ by doing convolution in the start and in the end of binpow.


\import{FFT-on-rails.tex}

